# IA_V3 â€“ Chat IA avec Ollama et gestion avancÃ©e des conversations

## ğŸ“Œ Description
Ce projet permet dâ€™interagir avec un modÃ¨le IA local via **Ollama** (par dÃ©faut `mistral`), tout en gÃ©rant automatiquement :
- La sauvegarde des conversations (`/sav`)
- Le chargement de sessions prÃ©cÃ©dentes
- Le renommage des conversations
- La conservation du contexte Ã  chaque Ã©change
- Des logs dÃ©taillÃ©s dans des fichiers sÃ©parÃ©s

## ğŸš€ NouveautÃ©s
- **Centralisation des constantes** dans `config.py` :
  - ParamÃ¨tres Ollama (`OLLAMA_BASE_URL`, `DEFAULT_MODEL`, `OLLAMA_TIMEOUT`)
  - RÃ©pertoires (`SAVE_DIR`, `LOGS_DIR`)
  - Formats de fichiers de sauvegarde
  - Messages systÃ¨me et prÃ©-enregistrÃ©s
- **RÃ©organisation des loggers** :
  - `core/logging/logger.py` â†’ Logger global (`debug.log`)
  - `core/logging/conv_logger.py` â†’ Logger conversationnel (par session)

## ğŸ“‚ Structure du projet
IA_V3/
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ chat_manager.py
â”‚ â”œâ”€â”€ ollama_client.py
â”‚ â”œâ”€â”€ sav_manager.py
â”‚ â”œâ”€â”€ commands.py
â”‚ â”œâ”€â”€ logging/
â”‚ â”‚ â”œâ”€â”€ logger.py
â”‚ â”‚ â””â”€â”€ conv_logger.py
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ sav/
â”œâ”€â”€ config.py
â”œâ”€â”€ main.py
â””â”€â”€ README.md


## ğŸ–¥ï¸ Utilisation
```bash
python main.py

ğŸ“œ Commandes disponibles
Commande	Description
/q	Sauvegarder la conversation et quitter
/exit	Quitter sans sauvegarder
/help	Afficher la liste des commandes
/rename NOM	Renommer la conversation actuelle
/msg1	Demande prÃ©-enregistrÃ©e 1
/msg2	Demande prÃ©-enregistrÃ©e 2
/load NOM	Charger une conversation sauvegardÃ©e
ğŸ—‚ï¸ Sauvegardes & Logs

    Conversations : sav/

    Logs techniques : debug.log

    Logs conversationnels : logs/


