# ğŸ“˜ Mistral Tests â€“ Configuration optimisÃ©e

Ce dossier contient une configuration **Ollama Modelfile** pour exÃ©cuter Mistral 7B en version optimisÃ©e vitesse, adaptÃ©e aux benchmarks de code Python courts.

---

## ğŸ“‚ Contenu

* `Modelfile` : configuration Ollama (sans extension).

---

## âš™ï¸ Construction du modÃ¨le

Depuis ce dossier :

```bash
ollama create mistral-tests -f Modelfile
```

Cela crÃ©e un nouveau modÃ¨le local nommÃ© **`mistral-tests`**.

---

## â–¶ï¸ Utilisation

Lancer le modÃ¨le optimisÃ© :

```bash
ollama run mistral-tests
```

Ou exÃ©cuter directement un benchmark :

```bash
python tools/benchmark/benchmark_mistral.py
```

*(modifier le script pour utiliser `mistral-tests` comme modÃ¨le si besoin)*

---

## ğŸ”§ ParamÃ¨tres choisis

* `FROM mistral:7b-instruct-q4_K_M` â†’ version quantisÃ©e Q4, plus rapide.
* `num_predict 200` â†’ suffisant pour gÃ©nÃ©rer une fonction Python complÃ¨te.
* `temperature 0.2` â†’ sortie stable et dÃ©terministe.
* `top_k 50` et `top_p 0.9` â†’ Ã©quilibre entre prÃ©cision et diversitÃ©.
* `num_ctx 512` â†’ contexte rÃ©duit, accÃ©lÃ¨re la gÃ©nÃ©ration.
* `repeat_penalty 1.1` â†’ Ã©vite les rÃ©pÃ©titions inutiles.

---

## ğŸ“ˆ Objectif

RÃ©duire le temps de rÃ©ponse lors des benchmarks automatisÃ©s tout en conservant un code correct et testable.
