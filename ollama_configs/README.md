# ğŸ“˜ Dossier `ollama_configs`

Ce dossier contient les **configurations personnalisÃ©es (Modelfile)** pour crÃ©er des variantes optimisÃ©es des modÃ¨les via **Ollama**.

---

## ğŸ“‚ Structure

```
ollama_configs/
 â”œâ”€â”€ mistral_tests/
 â”‚    â”œâ”€â”€ Modelfile   # Config optimisÃ©e pour Mistral
 â”‚    â””â”€â”€ README.md   # Explications et usage
 â”œâ”€â”€ deepseek_tests/
 â”‚    â”œâ”€â”€ Modelfile   # Config optimisÃ©e pour DeepSeek
 â”‚    â””â”€â”€ README.md   # Explications et usage
```

---

## â–¶ï¸ Utilisation

### CrÃ©er un modÃ¨le optimisÃ©

Depuis le dossier correspondant :

```bash
ollama create <nom-modele> -f Modelfile
```

Exemples :

```bash
cd ollama_configs/mistral_tests
ollama create mistral-tests -f Modelfile

cd ollama_configs/deepseek_tests
ollama create deepseek-tests -f Modelfile
```

### VÃ©rifier lâ€™installation

```bash
ollama list
```

Exemple de sortie :

```
mistral:latest
mistral-tests
deepseek-coder:6.7b
deepseek-tests
```

### Lancer un modÃ¨le optimisÃ©

```bash
ollama run mistral-tests
ollama run deepseek-tests
```

---

## ğŸ”§ ParamÃ¨tres courants dans les Modelfile

* `num_predict` â†’ limite le nombre de tokens gÃ©nÃ©rÃ©s (200 pour fonctions Python).
* `temperature` â†’ contrÃ´le la variabilitÃ© (0.2 pour code stable).
* `top_k` et `top_p` â†’ contrÃ´lent lâ€™Ã©chantillonnage (valeurs Ã©quilibrÃ©es : 50 / 0.9).
* `num_ctx` â†’ taille du contexte (512 tokens pour plus de vitesse).
* `repeat_penalty` â†’ Ã©vite les rÃ©pÃ©titions (1.1 recommandÃ©).

---

## ğŸ¯ Objectif

CrÃ©er des variantes optimisÃ©es des modÃ¨les pour rÃ©duire la **latence** et amÃ©liorer la **stabilitÃ©** dans les benchmarks de code.
