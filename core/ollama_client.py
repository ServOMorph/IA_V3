# core/ollama_client.py
import requests
import logging
from pathlib import Path
from core.logging.conv_logger import setup_conv_logger
from datetime import datetime
import json
from config import OLLAMA_BASE_URL, DEFAULT_MODEL, OLLAMA_TIMEOUT


class OllamaClient:
    def __init__(self, base_url=OLLAMA_BASE_URL, model=DEFAULT_MODEL, timeout=OLLAMA_TIMEOUT, session_file=None):
        self.base_url = base_url
        self.model = model
        self.timeout = timeout
        self.history = []  # Ã©changes en mÃ©moire
        self.session_file = Path(session_file) if session_file else None

        # Nommer le logger avec le dossier de session, pas le fichier
        session_name = self.session_file.parent.name if self.session_file else "conversation"
        self.conv_logger, self.conv_log_file = setup_conv_logger(session_name)

    def send_prompt(self, prompt: str) -> str:
        if not prompt.strip():
            logging.error("Le prompt est vide.")
            return ""

        # Contexte depuis l'historique interne
        context = self._get_saved_conversation()

        # Prompt complet
        if context:
            full_prompt = f"{context}\n\n---\nðŸ‘¤ Vous : {prompt}\nðŸ¤– Ollama :"
        else:
            full_prompt = prompt

        # Log prompt
        self.conv_logger.info("------ NOUVEL Ã‰CHANGE ------")
        self.conv_logger.info(f"[PROMPT ENVOYÃ‰ Ã€ MISTRAL]\n{full_prompt}")

        url = f"{self.base_url}/api/generate"
        payload = {
            "model": self.model,
            "prompt": full_prompt,
            "stream": False
        }

        try:
            response = requests.post(url, json=payload, timeout=self.timeout)
            response.raise_for_status()
        except requests.exceptions.Timeout:
            logging.error("DÃ©lai dâ€™attente dÃ©passÃ© pour Ollama.")
            return ""
        except requests.exceptions.RequestException as e:
            logging.error(f"Erreur de connexion Ã  Ollama : {e}")
            return ""

        try:
            data = response.json()
        except json.JSONDecodeError:
            logging.error("RÃ©ponse JSON invalide reÃ§ue dâ€™Ollama.")
            return ""

        answer = data.get("response", "").strip()

        # Log rÃ©ponse
        self.conv_logger.info(f"[RÃ‰PONSE DE MISTRAL]\n{answer}\n")

        # Historique interne
        self.history.append({
            "prompt": prompt,
            "response": answer,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })

        return answer

    def _get_saved_conversation(self):
        """Reconstruit le contexte depuis self.history."""
        if not self.history:
            return ""

        lines = []
        for ex in self.history:
            # Messages systÃ¨me (role/content)
            if "role" in ex and "content" in ex:
                ts = ex.get("timestamp", None)
                if ts:
                    lines.append(f"--- {ts} ---")
                lines.append(f"[{ex['role'].upper()}] : {ex['content']}\n")
                continue

            # Ã‰changes classiques (prompt/response)
            ts = ex.get("timestamp", "")
            if ts:
                lines.append(f"--- {ts} ---")
            if "prompt" in ex:
                lines.append(f"ðŸ‘¤ Vous : {ex['prompt']}")
            if "response" in ex:
                lines.append(f"ðŸ¤– Ollama : {ex['response']}\n")

        return "\n".join(lines).strip()
