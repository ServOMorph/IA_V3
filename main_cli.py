# main.py
from core.chat_manager import ChatManager
from core.ollama_client import list_installed_models, OllamaClient
from config import DEV_MODE, DEFAULT_MODEL


def select_model():
    """Affiche les mod√®les install√©s et demande √† l'utilisateur lequel utiliser."""
    models_output = list_installed_models()
    if not models_output:
        return DEFAULT_MODEL

    # Split lignes, ignorer l'ent√™te "NAME ..."
    lines = [line for line in models_output.splitlines() if line.strip()]
    models = []
    for line in lines:
        parts = line.split()
        if parts[0].lower() == "name":  # ignorer l'ent√™te
            continue
        models.append(parts[0])

    if not models:
        print(f"Aucun mod√®le trouv√©, utilisation du mod√®le par d√©faut : {DEFAULT_MODEL}")
        return DEFAULT_MODEL

    print("=== S√©lection du mod√®le IA ===")
    for i, m in enumerate(models, 1):
        print(f"{i}. {m}")

    try:
        choice = int(input(f"S√©lectionnez un mod√®le (1-{len(models)}) [par d√©faut {DEFAULT_MODEL}] : ").strip())
        if 1 <= choice <= len(models):
            return models[choice - 1]
    except Exception:
        pass

    print(f"‚Üí Aucun choix valide, utilisation du mod√®le par d√©faut : {DEFAULT_MODEL}")
    return DEFAULT_MODEL


def main():
    # V√©rifier serveur Ollama
    if not OllamaClient.check_server():
        print("‚ùå Erreur : le serveur Ollama ne r√©pond pas sur /api/tags")
        print("üëâ Lancez-le avec :  ollama serve")
        return

    # Mode dev : choisir un mod√®le au d√©marrage
    if DEV_MODE:
        model = select_model()
    else:
        model = DEFAULT_MODEL

    chat = ChatManager(model=model)
    chat.start_chat()

if __name__ == "__main__":
    main()
